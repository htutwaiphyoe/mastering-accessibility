# How Accessibility Guidelines Fit into Automation

Accessibility automation is an important aspect of building quality software. You can maintain something easier when a computer can help to test it. You can also bake in a contract for _how_ something should work so that other devs (or yourself, in the future) are less inclined to break it without anyone noticing.

While automation can be helpful, it‚Äôs also challenging. Sometimes tooling doesn‚Äôt support your use case (or you‚Äôre locked into an old version of a library). It‚Äôs time consuming to experiment and find solutions that work.

There is also a misconception that everything in accessibility can be automated. It cannot. We still need humans to test things while building accessible digital experiences.

## What can be automated, and what can‚Äôt

<div className="grid grid-cols-2 gap-6 my-6 max-w-[680px]">
    <figure>
        <figcaption className="font-bold">Automated ü§ñ</figcaption>
        - HTML/ARIA validation
        - Form labels
        - Color contrast
        - Accessible names
        - Focus management
        - Specifying a language
    </figure>
    <figure>
        <figcaption className="font-bold">Manual üôã‚Äç‚ôÄÔ∏è</figcaption>
        - Focus order
        - Text alternative quality
        - Screen reader testing
        - Contrast over images/gradients
        - Error identification
        - Click events on DIVs
    </figure>
</div>
Estimates for how much of [WCAG](https://www.w3.org/TR/WCAG22/) we can automate are around 50% of accessibility issues by volume. And that‚Äôs only from one vendor, [Deque Systems](https://www.deque.com/automated-accessibility-testing-coverage/). You can review their [rule descriptions for axe-core here](https://github.com/dequelabs/axe-core/blob/develop/doc/rule-descriptions.md).

> Related: [Accessibility Conformance Testing (ACT) Rules Group](https://act-rules.github.io/pages/about) at the W3C

When it comes to accessibility automation, you have to write feature tests that cover various parts of your app. Your engineering team will know the most about how components should work. So your tests can be tailored for aspects that can be automated, like keyboard support, ARIA states, labels, and more.

Accessibility test APIs like Axe haven‚Äôt historically been able to detect click events on DIVs, just like blind users couldn‚Äôt. Tooling that does have the ability to detect a click event on a DIV still can‚Äôt tell whether it‚Äôs a legit DIV click event or a bad one. This is one reason why [manual testing is still critical](https://www.smashingmagazine.com/2018/09/importance-manual-accessibility-testing/).

## Create your own coverage

Write feature tests for your components that assert accessibility functionality that can be programmatically determined. Keyboard tests are great examples of this. They are fun to do with the latest tools like Testing Library and Jest. But it can be tricky to capture how a user interacts with a real browser in automated tests.

Let‚Äôs dig into what it takes to write automated accessibility tests so we can bake in quality in an effective way. It‚Äôs about striking the right balance of automation, reliable code patterns, QA, and persistence. And not writing [tautological tests](https://www.lithichor.com/2020/03/tautological-tests.html) or tests that get commented out.

My hope is that you don‚Äôt succumb to a culture of ‚Äúit‚Äôs too hard to make this accessible.‚Äù Find a way to work through it and bake meaningful accessibility assertions into your process.
